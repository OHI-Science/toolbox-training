[
["index.html", "Ocean Health Index Toolbox Training Chapter 1 Welcome", " Ocean Health Index Toolbox Training Ocean Health Index Team 2017-09-25 Chapter 1 Welcome OHI assessments use collaborative open software so that they are transparent and reproducible; we call this software the OHI Toolbox. Openness is an important part of how we work; we describe how and why in Lowndes et al. 2017, Nature Ecology &amp; Evolution: Our path to better science in less time using open data science tools. This book will train you to prepare for and use the OHI Toolbox. It can be used to teach workshops or for self-paced learning. This book is under active development and testing "],
["intro.html", "Chapter 2 Introduction 2.1 Tools and Resources", " Chapter 2 Introduction In development. data and models in the Toolbox, including reference points. - best practices: core and tailorable parts ## OHI conceptually ## Best practices ---> 2.1 Tools and Resources It might seem like a daunting task to plan and conduct a multi-disciplinary, multi-stakeholder, transparent, and highly collaborative assessment. But we have several open-science, collaborative tools to aid you in this process. All the tools we will introduce aim to streamline the collaboration process and keep all records of decision making in one place. The tools include: Google Drive folder to gather thoughts and plan for the assessment OHI Toolbox, or Repositories where you organize and prepare data, and calculate scores. It includes: Starter Repository, made of Rstudio and Github, to explore and prepare data Full Repository, an extension of the Starter Repository, to run the models, calculate scores, and produce reports 2.1.1 Google Drive folder In preparation of the Conduct phase of your project or your technical workshop, each OHI+ project is first provided a Google Drive folder. It contains presentations, workshop agenda, notes, and a OHI+ Planner. All materials are intended to be used during an OHI+ workshop and beyond. Why Google Drive? OHI is a long-term, highly collaborative process. To make working together with multiple team members effecient, you will use many open-science tools, including Google Drive, Rstudio, and Github. Lets start with collaborating in Google Drive, where all participants can view and edit the same materials, and take notes. The advantage of using a shared Google Drive folder is that all your decision-making and insights are collected here in one place, rahter than in disparate emails or notes, or lost without even being recorded. Let’s take a look inside and see how you can best use it. Presentations and workshop agenda are fairly self-explanatory. They will help you navigate the workshop. Notes will be used throughout the workshop. Rather than having individual participants taking their own notes and stitching them together later, your could assign a few master notetakers who collaboratively and simultaneously record questions and discussions in this one shared document, while others can focus on the discussion itself. Participants can refer back to these notes at any time online. OHI+ Planner will be used most often during the workshop and after. It is a spreadsheet that organize and explore existing data to suit your Goals, Pressures, and Resilience, and to help you finalize spatial boundaries of your assessment. How to use the Planner Let’s open the Planner and take a closer look together. There are three main sheets - Status data, Pressures data, and Resilience data, followed by examples and explanations of how to fill out the main sheets. After you have used the Planner to explore data availability and conceptually map out the assessment, you can start using the OHI Toolbox to further prepare the data for calculations. At the start of your conduct phase, you will first get your Starter Repository. 2.1.2 Starter Repository Starter Repo Full Repo website a place to communicate using the same workflow you use for analysis. "],
["planner-guide.html", "Chapter 3 OHI Planner 3.1 Overview 3.2 Data Planner spreadsheet 3.3 Status Data tab", " Chapter 3 OHI Planner The purpose of Chapter 3 is to help you think about data for your assessment in a structured way. This is a 1-hour hands-on training: you will be following along on your own computer and working with a copy of the demonstration repository that is used throughout this chapter. 3.1 Overview A successful OHI+ assessment depends on representative data and models. With so much (or sometimes so little) information out there, how do you select the optimal data to be included in your study? How do you develop models that best reflect the conditions of your ocean health? How do you keep track of ideas you have and decisions you make? Here we have developed a OHI Planner to guide you through this important, yet sometimes daunting, process of data selection and model exploration. We’ll start by exploring the columns in the spread sheet and what they are for, and then walk through examples of how to fill them out. 3.1.1 Prerequisites The OHI Data Planner is a document you can download online. It is housed in a Google Drive folder [link to it once it has a permanent location] that is shared with OHI participants before an OHI Technical Training workshop. Make sure you have access to the folder as there are other files in the folder to aid the process of the workshop. However, if you are using this document as a stand-alone document, you can downdoad it here directly. Click open the Planner, and let’s walk through it together. 3.2 Data Planner spreadsheet Information from the spreadsheet is not going to be used directly by the Toolbox. Rather, this Data Planner is built to help you think about data and start the collaborative OHI process before your technical team make calculations with R. So that participants who are not on the technical team can also contribute ideas here. The Data Planner serves as a way to track ideas of data and see what they look like or if they are possible to use for your assessment. It seems daunting to have to write down what you want the models to be, but here you can record simply what you’re thinking, and what the ideal would be. It’s a starting point that you can then share with your colleagues to think about together, and start looking for data. The data searching process is not a definitive phase of an assessment. You might find your initial data ideas not adequate or feasbile to use for calculations later, or they don’t fit into the spatial boundaries you wanted to use. That’s okay. OHI is an iterative process, and you can always come back to this spreadsheet and edit further. Having this spreadsheet thus serves as a collaborative note for your and your colleagues to record ideas for future references. There are three tabs to be filled out: Status Data, Pressures Data, and Resilience Data. Now let’s take a look at each one of them. 3.3 Status Data tab Open up the “Status Data” tab, you’ll see these headings, or columns to be evaluated for each goal: This sheet is colored to help structure your thinking as you consider data. Generally you would want to work through this Planner from left to right. But note that the process of building models, finding data, and defining spatial boundaries is iterative. You might work on those components simultaneously in order to strike a balance between an ideal approach and data limitations. Let’s walk through each header first. 3.3.1 Goals and subgoals In the Global assessment, we identified ten “goals” - universally valued benefits provided by the ocean. However, they might not be as relevant in your region. You may remove the goals that are irrelevant on the spreadsheet. The Baltic Sea region doesn’t get big storms because of its geography. The Coastal Protection goal is therefore irrelavent here and removed from this study. 3.3.2 Model + Data + Spatial Boundaries Goal models and Spatial Boundaries need to be considered simultaneously, particularly in the initial data gathering stage. Spatial boundaries based on political and geological boundaries are set at the beginning of a study, validated and maybe adjusted with data. For example, if you have 5 provinces to assess separately, and data for province 1 and 2 are reported together and difficult to tease apart, then you might need to consider combining region 1 and 2 into one region in your assessment. Let’s look at these individually: Represent goals with models Model approaches? You don’t need to decide on the mathmatical formula here. Together with the next “variables” column, this column mainly aims to get you start thinking of model approaches. Is the global OHI model adequate for your needs? What should the goal capture? What ideal variables best represent the goal? Before even thinking about data, let’s think broadly, in your study area, what variables, or characteristics, of a goal best represent the philosophy of it, regardless if there is data available? Sometimes we tend to constrain our model development with the data we know we have. You can build a more representative model by thinking through what are the most ideal variables (eg. popularity of a region among tourists) to capture information, then find data that best reflect those variables (eg. hotel vacancy rates? international flights to this region? surf shop revenue? cruise ship revenue? etc). Different OHI+ projects have been creative at how they represent this goal as data permits. Check out the OHI-Science portal, Goals page (ohi-science.org/goals) page. It can help you understand the philosophy of a goal and shares what has been done. Let that catalyze your discussions. Do any of the past approaches suitable, or are there other obvious variables to better represent your goal in your country/region? Another important factor that determines OHI scores is Reference Point, ie. what status of this goal can be awarded a score of 100? Has the government set a target to achieve? Is there a model region that has become a standard other regions should aspire to? Is there a historical point the regions should return to? Find data for your ideal or proxy model variables Choice of model variables and reference points are often limited by data availability, time frame, and resolution. The data columns are a place to catelog a list of the data that could work: from your knowledge, when you ask your colleagues, digging through databases online, etc. Add as many rows as you need to to record your ideas. Having this master sheet of ideas will help you keep track of your thoughts and make collaboration with your collegues easier. Years: Typically having only one year of data is not enough to objectively reflect the status and trend of a goal. Five years of data are recommended. If that’s not available, using fewing years of data is possible. Spatial resolution: When you find a data source (eg. national poverty level), you might need to be disaggregate, or separate the data from large-scale (eg. national) to small-scale (eg. provential). You could contact the agency that publishes the data and see if they have gathered small-scale data. If that’s not possible, there are means (eg. GIS) to separate the large-scale data to local scales, although that could reduce the accuracy of the data. 3.3.3 Examples Now we have run through the basic theories behind each column, let’s walk through a few examples together over the next few panels of spreadsheets (Example 1 - 4). Example 1 - (Model &amp;) Variables Models are relationships among variables. Before gathering any data, think about ideal variables that could represent the goal. How could each variable be relevant/representative of ocean health? In this example, artisanal fishing opportunities measure whether people who need to fish on a small, local scale have the opportunity to do so. Thus the variables need to reflect the need for artisanal fishing, how easy or hard it is for fishermen to access ocean resources when they need them, and the sustainability of harvest of all fish stocks that fishermen use. The number of artisanal fishermen and/or the number of people below poverty line could reflect the need for artisanal fishing. Fish stock health can tell the sustainability of fishing in the region. Catch might be unsuitable, because it reflects the amount fished in the past, not the sustainable capacity for artisanal fishing. The fish stocks might have been over- or under- fished in the past. Gas price and number of ports could limit the fishermen’s ability to access ocean resources. As you might have noticed, to the right side of the sheet, there is a column for notes. In this case for Artisanal Fishing Opportunities (AO), Fish catch is deemed not suitable for the reasons stated above. It’s just as important to document the rationales for excluding a data source as it is to record why you included one. Example 2 - Data These few columns detail the data you find for each of the variables you decided suitable for your model. Are data available? For fish stock health, there is no readily accessible datasets. So this variable can’t be used in your study. But other variables seem to have data. Are they from a credible source? The quality of your assessment depends on the quality of your data. Government agencies (eg. Energy Information Administration), or research institutes tend to be more credible. How many years does it cover? As OHI measures trend for each goal, the trend is derived from ocean health status over time, ideally 5 years. In this case, there is sufficient data (1950-2016). Also, what’s the spatial resolution of this source? Spatial resolution should be compatible with the geopolitical boundaries of the regions in your study area. If the source only provides a national average, but the assessment requires provincial-level data, you need to look further. Example 3 - Spatial resolution As mentioned above, data should be disaggregated to the regional level that you determine to be the optimal spatial boundaries of your study. In the data exploration process, however, you might find that the geopolitical boundaries you initially thought to be ideal are not supported by data. For example, if region 1 and 2 do not have independent data - that data can only be disaggregated from national level data, and region 1 and 2 may end up with non-distinguishable data, you might consider combining region 1 and 2 into the same region for your assessment. Sometimes there isn’t data available, and sometimes data isn’t relevant to a region, e.g. if there are no mangroves growing in Region 4. So it’s important to have a system for distinguishing these two things. Here, we’ll use NA if it’s not relevant; that’s the syntax that R and the OHI Toolbox will use so we can be consistent. When data are not available but they should be, here we’ll mark it with an N. “NA” is used when there should be no data for this region. In this example, if no one lives in region 4, there would be no Livelihoods data for this region. Example 4 - Reference Point Reference points, or targets, are essential for rescaling and scoring. For example, if the target number of fishermen is 100, and the data only records 50, that could bring AO score down to 50. What the reference point for the indicators (or goal) should be? It could be from published policy targets, scientific studies, etc. It is not necessary that each indicator has a reference point, although most indicators need a reference point for rescaling. Gas prices fluctuates often. It’s difficult to set a reference point where it’s optimal. You could set the reference point to be "],
["data-science.html", "Chapter 4 Open data science 4.1 RStudio-GitHub workflow 4.2 How to learn", " Chapter 4 Open data science This chapter is under development. OHI assessments use collaborative open software so that they are transparent and reproducible. Openness is an important part of how we work; we describe how and why in Lowndes et al. 2017, Nature Ecology &amp; Evolution: Our path to better science in less time using open data science tools, and at ohi-science.org/betterscienceinlesstime. The OHI Toolbox depends upon the ‘open data science tools’ R, RStudio, Git, and GitHub. They are free to download and use, they are cross-platform (meaning they work on OSX and Windows), and they can be used to help organize, create, reproduce, and communite collaborative analyses. And that’s what OHI is all about! But something important is that these skills are transferrable; they are not only relevant to OHI but will serve you well for your other projects in the future. 4.1 RStudio-GitHub workflow The OHI Toolbox depends upon R, RStudio, Git, and GitHub and is important for reproduciblity, collaboration, and communication. You’ll get your computer set up with these tools and you will get into a workflow working from RStudio and syncing your work online to GitHub; hence, we call this the RStudio-GitHub workflow. 4.2 How to learn We are writing training materials for a 2-day intensive workshop to teach R, RStudio, Git, and GitHub so that you are best equipped to practice these skills and start working with the OHI Toolbox. Until these materials are finished, please use this 2-day self-paced workshop: Reproducible Science with RStudio and GitHub, which were developed by our team for a Software Carpentry workshop in 2016. There are also many resources available online, which we list here. We highly recommend Hadley Wickham &amp; Garret Grolemund’s R for Data Science and Jenny Bryan’s Happy Git with R. https://github.com/OHI-Science/bhi - http://ohi-science.org/mhi/ https://github.com/OHI-Science/mhi - http://ohi-science.org/ohi-global/ https://github.com/OHI-Science/ohi-global ### Background on branches: master and gh-pages #### What you need to know super powerful; parallel universe workspace. we'll just be taking advantage of the gh-pages, special branch. #### Setting up #### Switching branches - make sure you've committed and pushed before switching (I compulsively pull each time again, just to be sure) - if you have scripts open, it may say that they don't exist anymore and would you like to delete them. Say yes. They do exist, just in a different branch #### Updating content ---> "],
["toolbox-ecosystem.html", "Chapter 5 Toolbox Ecosystem 5.1 Overview 5.2 Prerequisites 5.3 main repository folder 5.4 Prep folder", " Chapter 5 Toolbox Ecosystem 5.1 Overview Welcome to the OHI Toolbox, the engine behind all OHI assessments. The Toolbox is an ecosystem of R scripts and data files, organized in folders and sub-folders. In this chapter, we will learn how the Toolbox is structured - where you would store data, modify models, make calculations, as well as record decision-makings. This tutorial will take roughly 30 minutes. The Toolbox ecosystem introduced here is the same in any assessment. So, if you want to explore the goal model for the Gulf of Guayaquil assessment for example, you could navigate to their models in the same way. Let’s get started! 5.2 Prerequisites Before the training, please make sure you have done the following: Have up-to-date versions of R and RStudio and have RStudio configured with Git/GitHub https://cloud.r-project.org http://www.rstudio.com/download http://happygitwithr.com/rstudio-git-github.html Fork the toolbox-demo repository into your own GitHub account by going to https://github.com/OHI-Science/toolbox-demo, clicking “Fork” in the upper right corner, and selecting your account Clone the toolbox-demo repo from your GitHub account into RStudio into a folder called “github” in your home directory (filepath “~/github”) Get comfortable: be set up with two screens if possible. You will be following along in RStudio on your own computer while also watching an instructor’s screen or following this tutorial. Now you have set up your computer, let’s open the toolbox-demo repository on your computer, and go from there. 5.3 main repository folder When you first open the repository, you’ll encounter the following files and folders. Note: if you have a starter repository, you’ll have a prep folder but not a scenario folder. Overall, all the main files you will see are either of the two file types: .csv files contain data inputs or configuration information. .R or .Rmd scripts are written in the programming language R and use data inputs for processing and calculations. Among all the files on your screen, the most important files are: install_ohicore.r. ohicore is the backbone software package of the Toolbox. It is a R package of functions that contain all the core operations for the data and models that you provide for your assessment, and it will calculate OHI scores. You don’t need to interact with or see the inside of ohicore yourself during the assessment, but you do need to install this software package once at the start of your assessment by running this script. prep is a data preparation folder. As the name suggests, this is where you will store raw and/or intermediate data, explore and format those data, and make trial runs of different models. You will spend roughly the first half of your time during an assessment here. region2016 is the scenario folder. The scenario folder is probably the most important folder within the repository. It contains all of the inputs needed to calculate OHI scores, and you will modify these inputs when conducting your assessment. By default it is named regionYEAR (e.g. cnc2016 for New Caledonia 2016) to indicate that the assessment is conducted at the region scale (province, state, district, etc.), based on input layers and goal models used in the most recent global assessment (e.g. 2016). README.md file accompanys most folders or files, as you will discover. It’s a place to take notes for yourself, your team, and anyone interested in the future. Let’s take a closer look at the prep and region2016 folders. 5.4 Prep folder Click on prep and let’s see what’s inside: Within prep, there is a sub-folder for each goal and subgoal, as well as pressures and resilience. These folders are meant to help you be organized, but if you have another way you’re welcome to go ahead with your own way. Note that some goals depend on the same data and thus data can be prepared into layers from one place instead of for each goal. This is the case for goals dependent on habitat data: CP, CS, HAB, and goals dependent on species data: SPP, ICO. Click on the ‘CW’ folder. Within each goal folder, there are typically a .Rmd script and a sub-folder to contain data. The CW_data_prep.Rmd document is a script where you will explore your raw data, format the data, try different models, make graphs and maps, as well as document decision making. We will come back to this script in Chapter 6 to learn how to prepare data for calculations. We use RMarkdown (.Rmd) files because they can be rendered as webpages (for example, CW_data_prep.html in the same CW folder) and can help explain the data processing steps and motivation behind them in written language. Click ‘Knit’ from the RStudio editor or click on the .html file from the file pane and select ’View in web browser`, and you will see a clean, human-readable webpage that can be shared online and viewed by anyone. Now we’ve walked through the prep folder, let’s take a look at the scenario folder. Click back to the main toolbox-demo folder, and open the region2016 folder. 5.4.1 region2016 folder Again, this scenario folder contains all the data layers and scripts for you to calculate OHI scores. Let’s look into the sub-folders and see what they do. 5.4.1.1 layers folder &amp; layers.csv After you prepared your data layers in the prep folder, you will save them in the layers folder, and register them in layers.csv. (You will learn how to do so in Chapter 6). The layers folder contains individual data layers as .csv files for each goal and subgoal, named in a specific manner for easy organization and recognition, as shown here. layers.csv is a data registry for all the data layers in the layers folder. It’s also a directory for ohicore to find the exact data layers for calculations. The file itself is spreadsheet that’s best to be opened in a spreadsheet editor such as Microsoft Excel. 5.4.2 conf folder The conf folder includes important configuration files required to calculate OHI scores, as shown here. Most of the maneuvering in the Conduct phase of the assessment is done within this folder. There are both .R scripts and .csv files. Let’s see what they are. 5.4.2.0.1 functions.R This R script contains the equations for each goal and sub-goal model. Much of your time will be spent here modifying goal models with the data you prepared in prep folder. Each goal and sub-goal equation is stored as a separate function within the script. These functions calculate the status and trend using prepared layers saved in the ‘layers’ folder and registered in layers.csv. 5.4.2.1 pressures &amp; resilience There are four .csv files relating to pressures and resilience. pressures_categories.csv pressures_matrix.csv pressures_categories.csv pressures_matrix.csv They are spreadsheets that are best opened with Excel. Pressures and Resilience are two of the four dimensions used to evaluate each goal or sub-goal, along with Status and Trend that you calculate in functions.R. We will go through how to modify these tables in Chapter @ref(pressures resilience) later. Now, we won’t dwell on these files much except to show you where they are, but you can refer back to this section for the detailed information listed below when you get to Chapter @ref(pressures resilience) pressures_categories.csv This is a table to record the name of each pressures data layer, its category, and sub-category. Each data layer name is the same name that’s saved in the layers folder and is registered in layers.csv. Each layer falls under one of two categories - ecological or social pressures, and one of several sub-categories to further represent the origin of the pressure (e.g. climate change, fishing, etc), which is also indicated by a prefix of each data layer name (for example: po_ for the pollution sub-category). pressures_matrix.csv This is a table that indicates which individual pressures (stressors) affect which goal, sub-goals, or components, and weights them from 1-3 (a weight of 0 is shown as a blank). A higher weight indicates more negative impacts on that goal or component of the goal. These weights are relative to each row of the matrix (goal, sub-goal, or component). These weights are used in global assessments based on scientific literature and expert opinion, and you can modify the weightings if necessary for your assessment. The pressures matrix is the same as Table S25 in the Supplementary Information for Halpern et al. 2012. Each pressure (column) of the pressures matrix is the layer name of the pressures layer file that is saved in the layers folder and is registered in layers.csv, matching what’s recorded in the pressures_categories.csv. resilience_categories.csv Similar to pressures_categories.csv, this file contains information on each resilience data layer, including its name, category, and sub-category. Each resilience layer’s name is the same as the data layer to be saved in the layers folder and is registered in layers.csv. In addition, it also includes information on category type - ecosystem, regulatory, or social, indicating the origin of the resilience layer. Each resilience layer is also assigned a weight of 0-1, representing the level of resilience against pressures. Different from the values used in pressures matrix, the resilience weights depend on the level of information available. resilience_matrix.csv This is a table that indicates which individual resilience measures affect which goal, sub-goals, or components. The resilience matrix is the same as Table S26 in the Supplementary Information for Halpern et al. 2012. 5.4.2.2 config.R config.R configures labeling and constants appropriately. You will only need to modify this file when working with goals that have categories (example: habitat types or economy sectors) that are affected differently by pressures and resilience measures. 5.4.2.3 goals.csv goals.csv is another spreadsheet file that’s best opened in Excel. goals.csv has information about goals and sub-goals, and controls which goals are calculated, and how they are represented in figures. If a goal exists in this list, it will be calculated, and needs an accompanying function in functions.r. Here are the columns within goals.csv: order_color &amp; order_hierarchy: the order to display in flower plots order_calculate: the order in which the goals and sub-goals are calculated for the overall index scores goal &amp; parent: indicates the relationship between sub-goals and supra-goals (i.e. goals - with sub-goals) weight: how each goal is weighted to calculate the final Index scores preindex_function: indicate what parameters are called to calculate scores for goals and - sub-goals in functions.r postindex_function: indicate what parameters are called to calculate scores for supra-goals in functions.r We have just gone over the files in the conf folder. To recap, the conf folder contains important configuration files required to calculate OHI scores, including functions.R, pressures and resilience files, etc. Now let’s take a step back to the region2016 folder, and check out what else is there. 5.4.3 configure_toolbox.r This script does the pre-checks before running goal models and calculate scores. It loads ohicore, calls all goal functions and data layers in the “conf” folder, and check that all data layers are registered properly. You are encouraged to use this script when you’re working on individual goal models. After you register data layers for a goal, or make any changes to the data layers, source this script before running model-specific functions in functions.R. 5.4.4 calculate_scores.R calculate_scores.R is a script you’ll come to use often. As the name tells us, it is a script to calculate OHI scores. Whenever you change any data inlayers, modify models in functions.R, and make changes to pressures and resilience, you could run this script and see how the OHI scores change. This script runs everything required to calculate OHI scores using the prepared layers the layers folder that are registered in layers.csv. Scores will be saved in scores.csv. 5.4.5 Recap The OHI Toolbox is a ecosystem of data layers and scripts, contained in folders and their sub-folders. The information in your Toolbox repository will interact with an R package called ohicore, which does the core operations to calculate OHI scores. You will need to install this package at the beginning of your assessment, and then call it as a library after that. As you begin your assessment, you will spend most of your time in prep folder, where you upload, explore, and format your data layers to be saved in the scenario folder region2016 for the next step of calculations. region2016 is a folder with all the data layers, files, and scripts you’ll need to calculate scores. There you will register finished data layers, modify goal models, modify pressures and resilience, calculate OHI scores, and make flowerplots. Now we have walked thorugh the files, how do they fit into the OHI process? Below is a figure that summarizes how each file will be used in relation to the steps you would take in an assessment for future reference. "],
["prep-data.html", "Chapter 6 Preparing data: Basic 6.1 Overview 6.2 Data Formatting requirements 6.3 Data Wrangling 6.4 Save and register data layers 6.5 Register data layers in layers.csv 6.6 Chapter Recap:", " Chapter 6 Preparing data: Basic The purpose of Chapter 6 is to introduce you to the basic workflow for preparing data for OHI. This is a a 2-hour hands-on training: you will be following along on your own computer and working with a copy of the demonstration repository (toolbox-demo) that is used throughout the this chapter. 6.1 Overview Preparing data takes the biggest chunk of time when you’re using the OHI Toolbox, even more than the final scores calculation itself. That’s when you explore raw data, see whether it fits with your ideal spatial boundaries and whether it makes sense to include it in your final calculations. If it does, you can format it further and save it as data layers, or Toolbox inputs for scores calculations. The Starter Repo 5 aims to help you wade through these important first steps of the assessment. Treat the preparatory, or “prep”, files as your notebook, calculator, and presentation of your work. Here, the process of data exploration is recorded and can be easily shared with anyone. In this chapter, we will go through the basic requirements and steps of preparing a data layer: understand the formatting requirements try a hands-on tutorial in which you can use sample data to format and save register a data layer Prerequisites Before the training starts, please make sure you have done the following: Have up-to-date versions of R and RStudio and have RStudio configured with Git/GitHub https://cloud.r-project.org http://www.rstudio.com/download http://happygitwithr.com/rstudio-git-github.html Fork the toolbox-demo repository into your own GitHub account by going to https://github.com/OHI-Science/toolbox-demo, clicking “Fork” in the upper right corner, and selecting your account. Clone the toolbox-demo repo from your GitHub account into RStudio into a folder called “github” in your home directory (filepath “~/github”). Note: If you’ve already forked and cloned the demo, you can instead pull from your computer to make sure you have the most recent versions of all the files. Get comfortable: be set up with two screens if possible. You will be following along in RStudio on your own computer while also watching an instructor’s screen or following this tutorial. After your toolbox-demo repository is set up, open the prep folder. It should look like this: Each goal and sub-goal has its own sub-folder, so you can store raw and intermediate data as you work in R Markdown (or R). It is highly recommended that data preparation occurs in the prep folder as much as possible, as it will also be archived by GitHub for future reference. But before we start preparing a data layer, let’s first go over the data formatting requirements. 6.2 Data Formatting requirements A data layer is a data file used to calculate scores. The global analysis included over 100 data layer files, and there will probably be as many in your own assessments. Each data layer (data input) has its own .csv file. These data layers are combined to calculate goal scores, meaning that they are inputs for status, trend, pressures, and resilience. The OHI Toolbox expects each .csv file to have: data for every region within the study area a unique region identifier (rgn_id) associated with a single score or value. data organized in ‘long’ format - as few columns as possible. (You can read more about long formatting here) OHI goal scores are calculated at the scale of the reporting unit, which is called a ‘region’ and then combined to produce the score for the overall area assessed, called a ‘study area’. For example, the U.S. is a study area, and each coastal state is a region. In addition, to calculate trend, input data should be available as a time series for at least 5 recent years - and the longer the better, as this can be used in setting temporal reference points. Finalized data layers have at least two columns: the rgn_id column and a column with data identified by its units (eg. km2 or score). There often may be a year column or a category column (for natural product categories or habitat types). Below are examples of two different data layer files: tourism count (tr_total.csv) and natural products harvested (np_harvest_tonnes.csv). They show information for a study area with 4 regions. Each region has multiple years of data. And the second data layer has an additional ‘categories’ column for the different types of natural products that were harvested. In this example, the two data layers are appropriate for status calculations with the Toolbox because: At least five years of data are available There are no data gaps Data are presented in ‘long’ or ‘narrow’ format When data gaps, temporal or spatial, are inevitable, various gap-filling techniques can be used. We won’t go through the details here. For more information and examples, visit OHI Manual 6.3 Data Wrangling So how do we get from raw data to a data layer that looks like the ones shown above? When we first access a data set, we often don’t know whether it is suitable for our purpose, or if it provides adequate information. Raw data can be in a different format than the desired long format and have extra or incomplete information. The main task of data preparation is to comb through the raw data, combine different sources, and sometimes fill in the information gap. We call this process “data wrangling.” For reproducibility and transparency, it is also good practice to record and share the decision-making process - trials and errors, why you decide to include, or more importantly, exclude a certain data source. Fortunately, we can take notes on the data exploration process and code in one place! Here is an example of a data prep document. Let’s give it a try to make one just like this. Now let’s switch to the demo repo. Today we will use the Clean Water (CW) goal as an hands-on example. We will get sample secchi depth data, as an indicator of water clarity. Click on the CW folder and open CW_data_prep.Rmd. We will follow the tutorial from there. 6.4 Save and register data layers Note: if you are preparing data from your Starter/Prep repository, you won’t have the layers folder and layers.csv. You won’t be able to do the following steps until you have the Full repository. After you have successfully processed a data layer, and it can be used by the Toolbox for calculations, it needs to be saved and registered here: layers folder is where all data layers live, and where the Toolbox pulls a layer out when needed. layers.csv is a giant spreadsheet that contains information about each layer - which goal it is used for, filename, column names, etc., and it will direct ohicore to appropriate data layers during calculations. Let’s first save the layer. You can do that in the prep script. Let’s switch back to the Demo repository, and follow the last section. 6.5 Register data layers in layers.csv After we have saved a data layer in layers folder, we will catalogue the layer in layers.csv. ` If a layer simply has a new filename, only the filename column needs to be updated: However, if a new layer has been added (for example when a new goal model is developed), you will open layers.csv in a spreadsheet software (i.e. Microsoft Excel), add a new row in the registry for the new data layer and fill in the first eight columns (columns A-H): targets: Add the goal/dimension that the new data layer relates to. Goals are indicated with two-letter codes and sub-goals are indicated with three-letter codes, with pressures, resilience, and spatial layers indicated separately. layer: Add an identifying name for the new data layer, which will be referenced in R scripts like functions.R and .csv files like pressures_matrix.csv and resilience_matrix.csv. name: Add a longer title for the data layer. description: Add a longer description of the new data layer. fld_value: Add the appropriate units for the new data layer. It is the same as the column name in the data file, which will be referenced in R scripts in subsequent calculations. (example: area_km2) units: Add a description about the units chosen in the fld_value column above. Think about what units you would like to be displayed online when filling out “units.” (example: km^2) filename: Add a filename for the new data layer that matches the name of the .csv file that was created previously in the layers folder. fld_id_num: Area designation that applies to the newly created data layer, such as: rgn_id and fao_id. It is important to check that you have filled you the fields correctly, for instance, if “fld_value” does not match the header of the source data layer, you will see an error message when you try to calculate scores. Other columns are generated later by the Toolbox as it confirms data formatting and content. Let’s open your layers.csv from your Finder, and we will fill it out together from there: This is what the new line should look like: 6.6 Chapter Recap: Hooray! You have just learned: how to process data, save, and register a data layer for the OHI Toolbox! OHI data layer formatting requirements data for each region long format best to have at least five years of continuous data how to process a messy and large raw data layer (secchi depth data for CW goal) how to saved and register the prepared data layer Now the layer is ready to be used by the toolbox to calculate status and trend scores. We’ll see you at Chapter 6 7 to learn that! "],
["calcs-basic.html", "Chapter 7 Calculations: basic workflow 7.1 Overview 7.2 Review the Toolbox file ecosystem 7.3 Calculate with ‘out-of-the-box’ data and models 7.4 Calculate with tailored data 7.5 Explore configure_toolbox.r 7.6 Explore a goal model in functions.r 7.7 Calculate with tailored models 7.8 Calculate with tailored data and models 7.9 Chapter Recap", " Chapter 7 Calculations: basic workflow The purpose of Chapter 7 is to introduce you to the basic workflow for calculating OHI scores. This is a 2-hour hands-on training: you will be following along on your own computer and working with a copy of the demonstration repository that is used throughout this chapter. 7.1 Overview Calculating scores with the OHI Toolbox requires a tailored repository operating with the OHI R package ohicore. The tailored repo has information specific to your assessment — most importantly the data and goal models — and ohicore will combine these with core operations to calculate OHI scores. You will always start with a tailored repository that has data and models extracted from the most recent Global OHI assessment. This training will introduce the basic workflow for calculating scores. There are many ways to build from the ‘out-of-the-box’ tailored repo you have instead of starting an assessment from scratch. For example, you may want to just change underlying data sources within the models, or competely change the models which also requires new data layers and data sources. We will repeat the basic workflow four times, each time adding complexity. We will calculate scores with: ‘out of the box’ data and models extracted from the Global 2016 assessment tailored data (with ‘out of the box’ models) tailored models (with ‘out of the box’ data layers) tailored data and models (adding a new data layer / model variable) The workflow depends on the calculate_scores.r script found the scenario folder of any tailored repo. We’ll also dive deeper into the code itself, focusing particularly on required configuration in configure_toolbox.r and developing goal models in functions.r. This is a lot to cover in a 2-hour training, and the purpose is to give you big take home messages and experience for what you need to begin calculating scores. But the Toolbox has a lot of moving parts, and we cannot cover all of it here. There are a lot of details and other operations that we won’t get into here and that will be coming in future tutorials (including tailoring pressures &amp; resilience, and how to change subgoals). 7.1.1 Prerequisites Before the training, please make sure you have done the following: Have up-to-date versions of R and RStudio and have RStudio configured with Git/GitHub https://cloud.r-project.org http://www.rstudio.com/download http://happygitwithr.com/rstudio-git-github.html Fork the toolbox-demo repository into your own GitHub account by going to https://github.com/OHI-Science/toolbox-demo, clicking “Fork” in the upper right corner, and selecting your account Clone the toolbox-demo repo from your GitHub account into RStudio into a folder called “github” in your home directory (filepath “~/github”) Get comfortable: be set up with two screens if possible. You will be following along in RStudio on your own computer while also watching an instructor’s screen or following this tutorial. 7.2 Review the Toolbox file ecosystem Let’s quickly review some of the files you have in the toolbox-demo repo. Remember that the ecosystem structure of any tailored repo is the same, so as you learn to navigate through and calculate scores in this repo you are also learning how to navigate through and calculate scores in any other OHI assessment repository — yours or anyone else’s. This figure highlights the files we will focus on in this tutorial (others are grayed out). In our toolbox-demo repo, here are a few additional things to mention: our scenario folder is called region2016 goal models are R functions in conf/functions.r regions are listed in spatial/regions_list.csv. We have 17 here. 7.2.1 Run install_ohicore.r If you don’t already have ohicore installed, let’s do that now. ohicore is an R package developed by the OHI team that has all the essential core functions and supporting packages you will use to develop your assessment and calculate scores. You will install ohicore one time and then load its library from the toolbox-training repository whenever you work on your assessment to gain access to all those functions and packages. Let’s open and source install_ohicore.r. 7.3 Calculate with ‘out-of-the-box’ data and models The first time we go through the basic workflow will be with ‘out-of-the-box’ data and models from the 2016 Global assessment. calculate_scores.r is a script that you’ll run a lot — both as a whole and piece-by-piece. It takes inputs (data and models) from the Toolbox and computes OHI scores, as the file name suggests. It has several components which we will explore in turn in the rest of the tutorial. calculate_scores.r will load the libraries you need and ohicore will check your book-keeping and configuration, and calculate OHI scores. Ultimately, it will save the scores for each goal and dimension in scores.csv. The ‘dimensions’ of OHI goal scores are Status, Trend, Pressures, Resilience, Likely Future State, and overall goal Score. Dimensions are calculated for each goal in a specific order, as we will see below. calculate_scores.r will combine information from your tailored repository and calculate scores with OHI core functions from ohicore. Open region2016/calculate_scores.r and let’s have a look at its operations. We will run it line-by-line. 7.3.1 Source configure_toolbox.R We will start by sourcing configure_toolbox.r from within calculate_scores.r. There is output printed to the console that lists all of the layers registered, and ends with any warning messages about the layers themselves. We will explore what is happening in configure_toolbox.r and how to interpret these warning messages further on; for now, let’s move on since we have not encountered an error. ## run the configure_toolbox.r script to check configuration source(&#39;~/github/toolbox-demo/region2016/configure_toolbox.r&#39;) # cc_acid # cc_slr # ... # tr_travelwarnings # Warning messages: # 1: In ohicore::CheckLayers(&quot;layers.csv&quot;, &quot;layers&quot;, flds_id = conf$config$layers_id_fields) : # Unused fields... # ico_spp_iucn_status: iucn_sid # 2: In ohicore::CheckLayers(&quot;layers.csv&quot;, &quot;layers&quot;, flds_id = conf$config$layers_id_fields) : # Rows duplicated... # ico_spp_iucn_status: 816 7.3.2 Run CalculateAll() Now let’s continue with the next operation in calculate_scores.r, which is to run CalculateAll(). Notice too that we are saving the output to a variable called scores. Note: the prefix ohicore:: is a way to be explicit that the CalculateAll() is part of the ohicore package. ## calculate scenario scores scores = ohicore::CalculateAll(conf, layers) CalculateAll() first calculates the Status and Trend for every goal and subgoal. These models are in your tailored repository’s functions.r (we will explore functions.r below). You can choose to add messages to print during calculation like is shown below for Mariculture (MAR). # Running Setup()... # Calculating Status and Trend for each region for FIS... # Calculating Status and Trend for each region for MAR... # 95th percentile for MAR ref pt is: 0.0758396517531756 # ... Next, we see output as CalculateAll() calculates Pressures and Resilience based on the pressures and resilience matrix tables in your tailored repository. For each, ohicore lists the subcategories that will be calculated, and identifies any mis-matches between data layers identified but not used or missing. We will learn more about the pressures and resilience matrices in a different Chapter. # Calculating Pressures for each region... # There are 6 pressures subcategories: pollution, alien_species, habitat_destruction, fishing_pressure, climate_change, social # These goal-elements are in the weighting data layers, but not included in the pressure_matrix.csv: # LIV-aqf # These goal-elements are in the pressure_matrix.csv, but not included in the weighting data layers: # CP-coral, CP-mangrove, CP-saltmarsh, CS-mangrove, CS-saltmarsh, HAB-coral, HAB-mangrove, HAB-saltmarsh, HAB-seagrass, LIV-ph, LIV-tran, CP-seaice_shoreline, HAB-seaice_edge, ECO-wte, LIV-wte, LIV-sb # Calculating Resilience for each region... # There are 7 Resilience subcategories: ecological, alien_species, goal, fishing_pressure, habitat_destruction, pollution, social # These goal-elements are in the resilience_matrix.csv, but not included in the weighting data layers: # CP-coral, CP-saltmarsh, CS-saltmarsh, HAB-coral, HAB-saltmarsh, HAB-seagrass, CP-mangrove, CS-mangrove, HAB-mangrove, HAB-seaice_edge, CP-seaice_shoreline Finally, we see output as CalculateAll() combines the dimensions above in several ways. It calculates the Goal Scores and Likely Future State for each goal and subgoal. Then, it calculates ‘supragoals’, which are goals that have subgoals, for example Food Provision (FP), which has the subgoals FIS (Wild-caught Fisheries) and Mariculture (MAR). Finally, it calculates the overall Index score for the entire Assessment Area using an area-weighted average. # ... # Calculating Goal Score and Likely Future for each region for FIS... # Calculating Goal Score and Likely Future for each region for MAR... # ... # Calculating post-Index function for each region for FP... # Calculating post-Index function for each region for LE... # Calculating Index score for each region for supragoals using goal weights... # Calculating Likely Future State for each region for supragoals using goal weights... # Calculating scores for ASSESSMENT AREA (region_id=0) by area weighting... # Calculating FinalizeScores function... Following all the calculations are the warning messages, which are due to operations within functions.r, which you will be able to fix as you tailor your goal models. These warning messages are due to using goal models from the global assessment with just a subset of data from the global assessment we have extracted here for the toolbox-demo repository. # Warning messages: # 1: In left_join_impl(x, y, by$x, by$y, suffix$x, suffix$y) : # joining factors with different levels, coercing to character vector # ... # 8: In max(d$x, na.rm = T) : # no non-missing arguments to max; returning -Inf 7.3.3 Save scores variable as scores.csv Finally, we will save the output from CalculateAll(), a variable called scores, as a comma-separated-value file called scores.csv. ## save scores as scores.csv write.csv(scores, &#39;scores.csv&#39;, na=&#39;&#39;, row.names=F) We can inspect it and see that it is a long-formatted file with four columns for the goal, dimension, numeric region identifier, and score. goal dimension region_id score AO future 0 92.85 AO future 1 92.85 AO future 2 92.85 … … … … AO future 17 92.85 AO pressures 1 37.75 AO pressures 2 37.75 … … … … We have 17 regions in the toolbox-demo repo. An additional region 0 is the area-weighted combination of all regions. Note: each region in your assessment will have a numeric region identifer, called a region_id or rgn_id for short. You can see a list of all regions and corresponding identifiers in toolbox-demo/region2016/spatial/regions_list.csv 7.3.4 A note about error messages Hopefully this first time through calculate_scores.r you did not encounter error messages, but you definitely will as you move ahead. Error messages are often due to typos or miscommunications between what you tell R versus what it expects. You will encounter error messages due to R itself, and due to ohicore. Error messages often have human-friendly messages to alert you to what went wrong, and we are continually improving error messages you’ll encounter when you use ohicore so you can try to solve them more easily. Some commonly occurring errors and how to fix them can be found in the Troubleshooting section of the manual. Copy-pasting error messages into Google is also one of the best places to start. 7.3.5 Recap of first calculate_scores.r run We have just successfully run through the basic workflow to calculate OHI scores. It first runs configure_toolbox.r to load necessary data, functions, and packages, then it calculates all the components of OHI scores (status, trend, pressures, resilience, overall scores), and finally it saves the new OHI scores in a .csv file. We will build on this basic workflow, by exploring the operations above in more detail, and by updating the data, models, and configurations within the toolbox-demo repository. 7.4 Calculate with tailored data Now let’s run through this basic workflow a second time, building on what we’ve learned. Here, we will focus on one of the layers for the Artisanal Fishing Opportunity (AO) goal. We will prepare local data that will substitute Global OHI data for the data layer ao_access and recalculate scores without modifying the goal model itself. It’s a good idea to go to RStudio’s Session menu and select Restart R to make sure you have a clean working directory. 7.4.1 Prepare and save our data layer While Chapter 6 shows in detail how to prepare data layers, save them in the “layers” folder, and register them so the Toolbox knows where to find them, we have prepared a shorter example with AO for our purposes here. Open toolbox-demo/prep/AO/access_prep.R and source it after reading it through. The result will be a new data layer called “ao_access_demo2017.csv” saved to the “layers” folder, and you should see that there is a new file saved in your Git window. 7.4.2 Register our data layer Now that we have prepared and saved our data layer, we’ll register it in layers.csv. layers.csvis a registry that will direct ohicore to appropriate data layers, and has information about each data layer — which goal it is used for, filename, column names, etc. For further detail see Chapter 6. Since we have tailored an existing data layer that is already registered, we just need to have it point to our new data layer under the “filename” column. Open region2016/layers.csv in a spreadsheet software (i.e. Microsoft Excel or Open Office). Next, find ao_access in the “layer” column. The current filename it is associated with is “ao_access_gl2016.csv”. Update that to say “ao_access_demo2017.csv” — the new data layer you just saved. Close Excel. IMPORTANT! Be sure to close Excel after you have made these edits. On a PC, having layers.csv open in Excel will prohibit it from being accessed from R, and the Toolbox needs access to calculate scores! 7.4.3 Rerun calculate_scores.r Now, let’s rerun calculate_scores.r. ohicore will now use your tailored data when it creates the “ao_access” layer because you’ve registered it in layers.csv and the file is available in the layers folder. 7.4.4 Checking our work and syncing Whenever there are changes made to your files (additions, deletions, and modifications), you will be notified in the Git window, since Git is tracking the files in this repo. This is a good place to confirm you have did the things you set out to do, and you can also see if you errantly did anything you didn’t mean to. So here, you added a new data layer and after calculating scores you expect to see changes to AO scores in score.csv. layers.csv will also change because ohicore will update fields in this file as it runs through its checks. But we don’t expect any other files to change at this point, so let’s make sure that’s true. Now is a good time to commit this work and sync to GitHub. That way, the work we’ve done is committed together and we will have a clean slate (from a Git sense) moving forward. I’ll use the commit message “toolbox-training: tailor data layer and rerun calculate_scores.r” 7.4.5 Recap of second calculate_scores.r run One way to tailor your toolbox is to modify an existing data layer. We have just run through the basic workflow a second time. This time we successfully substituted the Global OHI data layer ao_access with new data, which includes saving it in layers folder registering it in layers.csv, and reran calculate_scores.r without modifying the goal model itself 7.5 Explore configure_toolbox.r So now let’s take a closer look at configure_toolbox.r, the first script called from calculate_scores.r. configure_toolbox.r combines everything required to calculate OHI scores and checks that they are properly formatted, and will minimize potential errors later on. It makes sure that your data and goal models are ready to be used to calculate scores. Any time you make a change to a data layer or a goal model and want to recalculate scores, you will need to re-run configure_toolbox.r to have ohicore operate on the most up-to-date information. You can click “Source” to run all the lines. We’ll walk through line-by-line now. 7.5.1 Load libraries and set working directory The first two things that configure_toolbox.r does is to set up your working environment. First, it loads ohicore and any R packages that will be needed as you work with functions.r: tidyverse (which includes dplyr and tidyr) and stringr. As you need other packages you can add them here to load. Second, it sets your working directory to your assessment’s scenario: “region2016”. ## load ohicore and tidyverse if (!&quot;ohicore&quot; %in% (.packages())) { suppressWarnings(require(ohicore)) library(tidyverse) # install.packages(&#39;tidyverse&#39;) library(stringr) } ## set working directory to the scenario that contains conf and layers directories setwd(&#39;~/github/toolbox-demo/region2016&#39;) 7.5.2 ohicore::Conf() Next, the Conf() function from ohicore prepares for the next steps of running the Toolbox, and calls forth everything you need to calculate scores: all data layers (for goals, pressures, resilience) goal functions, and other OHI parameters that determines how OHI scores are calculated ## load scenario configuration conf = ohicore::Conf(&#39;conf&#39;) 7.5.3 ohicore::CheckLayers() The CheckLayers() function from ohicore checks that data layers are properly formatted and registered (e.g., that each data layer in layers.csv is present in the layers folder), and returns a list of all of the layers that are registered. Check to make sure ours is there. This is a gate-keeping step by to make sure the data layers you’ve entered are in the right format and can be read by ohicore properly. ## check that layers in the layers folder match layers.csv registration. ohicore::CheckLayers(&#39;layers.csv&#39;, &#39;layers&#39;, flds_id=conf$config$layers_id_fields) 7.5.3.1 Warning messages Warning messages alert you to problems with specific layers: this is showing that there are unused fields and duplicate rows. These warning messages are not a problem now (they are a byproduct of extracting this repo based on Global OHI assessments; you’ll be changing this layer anyways). Warning messages: 1: In ohicore::CheckLayers(&quot;layers.csv&quot;, &quot;layers&quot;, flds_id = conf$config$layers_id_fields) : Unused fields... ico_spp_iucn_status: iucn_sid 2: In ohicore::CheckLayers(&quot;layers.csv&quot;, &quot;layers&quot;, flds_id = conf$config$layers_id_fields) : Rows duplicated... ico_spp_iucn_status: 816 You will encounter error messages as you develop your own assessment. These messages intend to alert you that there are errors in data entry. Some common errors are: improper formatting or missing columns in your data layer typos or misnamed columns 7.5.4 ohicore::Layers() The final operation in configure_toolbox.r is the Layers() function from ohicore, which combines all the information from the layers files and layers.csv into a single R object. This object will be used in functions.r. ## load scenario layers for ohicore to access. layers = ohicore::Layers(&#39;layers.csv&#39;, &#39;layers&#39;) 7.5.5 Recap of exploring configure_toolbox.r We have explored each component of configure_toolbox.r, which sets up for calculations by loading ohicore and other necessary R packages, and double check that your data layers are formatted and registered properly. 7.6 Explore a goal model in functions.r Remember from calculate_scores.r that after configure_toolbox.r runs, the next thing that happens is that CalculateAll() runs through the goal models and calculates Status and Trend. Status and Trend calculations are within R functions for each goal model in functions.r. functions.r is in the conf folder of your tailored repo. We can find it in our toolbox-demo repo. functions.r is a big list of all goal models in the assessment. Each goal model is an individual R function that calculates Status and Trend, and you will modify the goal model within the confines of each function. You can run all of them at the once or each individually. Let’s look at the goal models for Artisanal Fishing Opportunity (AO) to continue our example. It has models developed from the most recent global assessment as a place for you to start ‘out-of-the-box’. Tip: Clicking the bottom left corner of Console will show you a drop-down menu of all functions. It’s a shortcut to jump to the appropriate section or goal model When you modify an individual goal model, you will only work within the function’s curly braces { }. The following things happen in each goal model: load specific data layers (using ohicore::SelectLayersData()) calculate Status scores calculate Trend scores combine Status and Trend scores format and return the scores object Throughout functions.r, you will see syntax from the tidyverse package that you loaded in configure_toolbox.r. It contains the commonly used data-wrangling functions you’ll need in almost every analysis, and enables chaining: %&gt;%. To learn more, take a look at tidyverse.org. This cheatsheet is also a helpful guide with quick references to each function. Tip: changes need to be saved before it is recorded by Git and reflected in the Git window. When new changes are made, the title of your R script will be shown in red color. It will change back to black once the changes are saved. 7.6.1 Load specific data layers with SelectLayersData() SelectLayersData() is an ohicore function to call the appropriate data layers by its layer name registered in layers.csv (e.g. ao_access). Run this chunk of code and the data layers will be loaded, joined, and ready to be manipulated further: ## read in individual data layers d1 &lt;- SelectLayersData(layers, layers = &#39;ao_access&#39;, narrow=TRUE) %&gt;% select(region_id = id_num, access = val_num) d2 &lt;- SelectLayersData(layers, layers = &#39;ao_need&#39;, narrow=TRUE) %&gt;% select(region_id = id_num, year, need = val_num) ## join data layers into single data frame (see RStudio cheatsheets) ao_data &lt;- left_join(d1, d2, by=&quot;region_id&quot;) Tip: it’s always a good idea to check what your data looks like and make sure there are no glaring errors. A couple of commonly used functions are head(), summary(), and str() 7.6.2 Goal model The goal model that was developed for global assessments and described in Halpern et al. 2012 Supplemental Information (p. 19) states that the status for this goal is therefore measured by unmet demand (Du), which includes measures of opportunity for artisanal fishing, and the sustainability of the methods used. \\[ D_{U} = (1 - need) * (1 - access) \\] \\[ status = (1 - D_{U}) * sustainability \\] And this is how it looks in R: ao_model &lt;- ao_data %&gt;% mutate(Du = (1 - need) * (1 - access)) %&gt;% mutate(status = (1 - Du) * sustainability) # head(ao_model); summary(ao_model) 7.6.3 Calculate Status The next operation in the AO function is to calculate status. Here, it essentially filters out the most recent year. Let’s run this together; you’ll have to also run the sustainability and status_year variables that are read in as part of the function. ## &quot;mutate&quot; is another commonly used function from dplyr that allows you to add a new column to the data frame ## Note that &quot;sustainability&quot; and &quot;status_year&quot; have been defined at the start of the AO function sustainability=1.0 status_year = 2015 # status: status scores are typically the most recent year of all the years you have calculated. ao_status &lt;- ao_model %&gt;% filter(year==status_year) %&gt;% select(region_id, status) %&gt;% mutate(status=status*100) 7.6.4 Calculate Trend Next is the Trend scores. They are typically based on linear regression of status scores from the most recent five years. # choose trend years (eg. most recent five years) trend_years &lt;- (status_year-4):(status_year) adj_trend_year &lt;- min(trend_years) ao_trend = ao_model %&gt;% group_by(region_id) %&gt;% # linear model: do(mdl = lm(status ~ year, data=., subset=year %in% trend_years), adjust_trend = .$status[.$year == adj_trend_year]) %&gt;% # extract the coefficient of year and produce a trend score summarize(region_id, trend = ifelse(coef(mdl)[&#39;year&#39;]==0, 0, coef(mdl)[&#39;year&#39;]/adjust_trend * 5)) %&gt;% # make sure that the scores are between -1 and 1 mutate(trend = ifelse(trend&gt;1, 1, trend)) %&gt;% mutate(trend = ifelse(trend&lt;(-1), (-1), trend)) %&gt;% mutate(trend = round(trend, 4)) 7.6.5 Scores variable: combining Status and Trend Combining the Status and Trend into the scores variable involves selecting only the region_id and score columns, and adding two more columns identifying score dimension (Status or Trend) and goal name. scores = ao_status %&gt;% select(region_id, score=status) %&gt;% mutate(dimension=&#39;status&#39;) %&gt;% rbind( ao_trend %&gt;% select(region_id, score=trend) %&gt;% mutate(dimension=&#39;trend&#39;)) %&gt;% mutate(goal=&#39;AO&#39;) The scores variable is something that you’ll see at the end of every goal model; ohicore will combine these all together when CalculateAll() runs. 7.6.6 Recap of exploring functions.r functions.r is a collection of goal models to calculate Status and Trend. Each goal is written inside an R function and can have the following steps: load specific data layers (using ohicore::SelectLayersData()) calculate Status scores calculate Trend scores combine Status and Trend scores format and return the scores object 7.7 Calculate with tailored models Now let’s run through the basic workflow a third time, this time modifying a goal model but keeping all data layers the same. We will do this without making any changes to the data layers at the moment. Modifying a goal model involves editing the operations within that goal’s model in functions.r. 7.7.1 Source configure_toolbox.r First let’s restart R and source configure_toolbox.r. We can do this from either calculate_scores.r or from configure_toolbox.r itself. 7.7.2 Tailor AO goal model Now, let’s go to functions.r and go back to the AO model. Let’s do something pretty simple to tailor the goal model. Let’s say we just wanted to divide the variable Du by 2 in the equation. ao_model &lt;- ao_data %&gt;% mutate(Du = (1 - need) * (1 - access)) %&gt;% mutate(status = (1 - Du/2) * sustainability) We can run the rest of the AO function line-by-line and inspect the scores variable at the end to see if everything looks OK. 7.7.3 Calculate scores, check, and sync Now let’s run the rest of calculate_scores.r and save scores.csv. We can use Git’s differencing feature to see how our scores have changed. This is a great way to double-check and error-check that things are working the way you expected. Let’s commit and sync. My commit message here will be “toolbox-training: tailor AO goal model with original data layer”. Let’s restart R before proceeding. 7.7.4 Recap of third calculate_scores.r run In this third time through the basic workflow, we updated the goal model without changing any of the data layers that it depends upon. Next up, we will add a new data layer for it to work with. 7.7.5 Troubleshooting If you’ve tailored a goal model function, you need to make sure that its output is still a data frame, and one that is not grouped. Otherwise, when you run calculate_scores.r, you may get a cryptic error. Examples of some of the ones we’ve seen are: # Error in left_join_impl(x, y, by$x, by$y, suffix$x, suffix$y, check_na_matches(na_matches)) : # Can&#39;t join on &#39;region_id&#39; x &#39;region_id&#39; because of incompatible types (integer / list) We are constantly improving ohicore with more human-readable error messages, but it is still best practice to ensure your goal model output is returning a dataframe. You can do this in a few ways. The way we commonly do this is by adding ungroup() or as.data.frame() as the final step before returning the scores variable at the end of a goal model function. 7.8 Calculate with tailored data and models The fourth and final example we will do in this chapter is to tailor a goal model by adding a new variable. This will mean that we will prepare, save, and register a new data layer and update the goal model in functions.r. It will be a combination of what we’ve done previously in this chapter. Let’s say we want to tailor the AO goal model by adding a new variable for poverty into the equation. \\[ D_{U} = (1 - (need + poverty) / 2) * (1 - access) \\] \\[ status = (1 - D_{U}) * sustainability \\] 7.8.1 Prepare and save our new data layer We will create the new data layer for poverty by running a script in the prep folder. Open toolbox-demo/prep/AO/poverty_prep.R and source the file after reading it through. The result will be a new data layer saved to the “layers” folder, and you should see that there is a new file saved in your Git window. 7.8.2 Register our new data layer Now that we have prepared and saved our data layer, we’ll register it in layers.csv. This time, since we have added an additional data layer that has not been previously registered, we need to add a new row. Open region2016/layers.csv in a spreadsheet software (i.e. Microsoft Excel or Open Office). Add a new row for “ao_poverty”, and fill in the following information. We’ve added the row near the other AO data layers. Note: you could also script updating layers.csv from your prep file (not illustrated). 7.8.3 Source configure_toolbox.r To use this layer as we develop our goal model, we need to source configure_toolbox.r. 7.8.4 Update the AO goal model We will need to do two things to update the goal model in functions.r. First, we’ll have to load our data layer with SelectLayersData(). You can copy-paste the following into your functions.r AO goal model and then run it after running status_year=2015; sustainability=1.0 to make sure everything is working properly: ## read in individual data layers d1 &lt;- SelectLayersData(layers, layers = &#39;ao_access&#39;, narrow=TRUE) %&gt;% select(region_id = id_num, access = val_num) d2 &lt;- SelectLayersData(layers, layers = &#39;ao_need&#39;, narrow=TRUE) %&gt;% select(region_id = id_num, year, need = val_num) ## add new poverty data layer d3 &lt;- SelectLayersData(layers, layers = &#39;ao_poverty&#39;, narrow=TRUE) %&gt;% select(region_id = id_num, year, poverty = val_num) ## join data layers into single data frame, including the new poverty data layer ao_data &lt;- left_join(d1, d2, by=&quot;region_id&quot;) %&gt;% left_join(d3, by=c(&quot;region_id&quot;, &quot;year&quot;)) Next, we’ll tailor the goal model itself. Here is how the goal model looks as an equation and in R: you can copy-paste this model into functions.r, replacing the existing model. \\[ D_{U} = (1 - (need + poverty) / 2) * (1 - access) \\] \\[ status = (1 - D_{U}) * sustainability \\] ## tailored goal model with poverty ao_model &lt;- ao_data %&gt;% mutate(Du = (1 - (need + poverty) / 2 ) * (1 - access)) %&gt;% mutate(status = (1 - Du) * sustainability) 7.8.5 Calculate scores, check, and sync Everything is looking good in functions.r and in the Git tab that we’re looking at as we go along. Now let’s restart R and rerun calculate_scores.r. We’ll see that scores.csv will also update, and we can check that only AO dimensions (except pressures and resilience since we haven’t changed them) and Index scores are affected. Let’s commit and sync. My commit message will be “toolbox-training: tailor AO goal model with a new data layer”. 7.8.6 Recap of fourth calculate_scores.r run In this run we combined what we have practiced in the previous two runs, and we successfully: created a new data layer, which includes preparing layer in the prep file, saving it in layers, and registering it in layers.csv added this new model parameter (ie. new layer) in AO model in functions.r reran calculate_scores.r and saw the changes reflected in Git 7.9 Chapter Recap We have completed Chapter 7 and successfully run through the basic workflow to calculate OHI scores with several variations using our toolbox-demo repository. Each variation involves the same basic workflow of bookkeeping and running calculate_scores.r, and will enable you to begin tailoring the Toolbox for your assessment. ‘out of the box’ data and models extracted from the Global 2016 assessment tailored data and ‘out of the box’ models tailored data and models tailored (new) data and models Also, a few best practices we have used throughout this training that are good to remember: Compulsively restart R Always check Git window after each change for expected changes Commit, then Pull before Push Rerun configure_toolbox.R after any data layer or model changes Save functions.R before the changes are reflected in Git window Close Excel before returning to R (this is less important on a Mac but will cause errors on a PC) "],
["calcs-advanced.html", "Chapter 8 Calculations: advanced workflow 8.1 Overview 8.2 Explore goals.csv 8.3 Round 1: Poke at it to see how it works 8.4 Round 2: Break it to see how it works 8.5 Adding a new goal 8.6 Adding subgoals 8.7 Modifying subgoals 8.8 Chapter recap 8.9 Changing subgoals", " Chapter 8 Calculations: advanced workflow In development. The purpose of Chapter 8 is to build off the basic workflow for calculating OHI scores and do a few more advanced things. This is a a 2-hour hands-on training: you will be following along on your own computer and working with a copy of the demonstration repository that is used throughout the this chapter. 8.1 Overview TODO: Recurring theme here: what goals are included in my assessment? Worth noting too that we’ll be improving goals.csv operates because there are some inefficiencies/things that are a bit error prone… Good practice to run calculate_scores.r and use Git window to check your work. TODO: add commits, sync to this. we’ll also be reverting a lot as we test things. 8.1.1 Prerequisites Before the training, please make sure you have done the following: Have up-to-date versions of R and RStudio and have RStudio configured with Git/GitHub https://cloud.r-project.org http://www.rstudio.com/download http://happygitwithr.com/rstudio-git-github.html Fork the toolbox-demo repository into your own GitHub account by going to https://github.com/OHI-Science/toolbox-demo, clicking “Fork” in the upper right corner, and selecting your account Clone the toolbox-demo repo from your GitHub account into RStudio into a folder called “github” in your home directory (filepath “~/github”) Get comfortable: be set up with two screens if possible. You will be following along in RStudio on your own computer while also watching an instructor’s screen or following this tutorial. Additionally, this chapter assumes you are familiar with content from Chapter 7, so review that first if needed. 8.2 Explore goals.csv This is the registry for goals. ohicore will use this list and make sure there are functions with the same names in functions.r. This is one of the things that does on in Conf()… Let’s open and inspect it in excel focus on a few columns (see ecosystem for more) note “goal” and “parent” This is where it happens: conf = ohicore::Conf(&#39;conf&#39;) 8.3 Round 1: Poke at it to see how it works The Toolbox won’t always give errors when you start changing things (work in progress), so let’s just see what some of these things look like. This is when using the Git tab to help you keep track of how things work REALLY helps. We’ll try it from registry -&gt; functions.r and then from functions.r -&gt; registry (goals.csv) 8.3.1 Delete a goal cell in goals.csv Eg delete “LSP” run calculate_scores.r what changed? 8.3.2 Remove a goal (whole row) in goals.csv Here we see “Index” scores change, “SP” scores change, and “LSP” scores get deleted. TODO: for both a goal and subgoal 8.4 Round 2: Break it to see how it works 8.4.1 Change preindex_function goals.csv it’s the preindex_function column that is critical for the functions. Let’s add a typo there. # Calculating Status and Trend for each region for HAB... # Error in eval(expr, envir, enclos) : could not find function &quot;HA&quot; 8.4.2 Add a new goal in goals.csv Just copy-paste. What do you think will happen? what’s the most important column? That’s right, preindex_function. This will fail at the scores calculation. scores = ohicore::CalculateAll(conf, layers) # Running Setup()... # Calculating Status and Trend for each region for FIS... # ... # ... # Calculating Status and Trend for each region for SPP... # Calculating Status and Trend for each region for EX... # Error in eval(expr, envir, enclos) : could not find function &quot;EX&quot; write.csv(scores, &#39;scores.csv&#39;, na=&#39;&#39;, row.names=F) # Error in is.data.frame(x) : object &#39;scores&#39; not found 8.4.3 Delete a goal model from functions.r won’t fail at Conf, but will at scores calc. # Calculating Status and Trend for each region for AO... # Error in eval(expr, envir, enclos) : could not find function &quot;AO&quot; # ... write.csv(scores, &#39;scores.csv&#39;, na=&#39;&#39;, row.names=F) # Error in is.data.frame(x) : object &#39;scores&#39; not found 8.5 Adding a new goal this is how to do it right. Need to add the row in goals.csv and the function in functions.r 8.6 Adding subgoals 8.7 Modifying subgoals TODO: how is this different than above? 8.8 Chapter recap goals.csv, adding goals, removing, changing subgoals. trend years. 8.9 Changing subgoals 8.9.1 Update goal call in goals.csv "],
["updating-your-website.html", "Chapter 9 Updating your website 9.1 Overview", " Chapter 9 Updating your website In development. 9.1 Overview make maps, flower plot TODO: add from NCEAS roundtable training "]
]
