# Calculations: basic workflow {#calcs_basic} 

## Overview

This is a 2-hour hands-on training. All training materials are below, and can also serve as a self-paced workshop without guided instruction. 

This training will introduce you to the workflow required to calculate OHI scores. Calculating scores requires the `ohicore` package working properly with your tailored repository. Your tailored repository will have information specific to your assessment, including formatted data layers and goal models that are written as `R` functions, and `ohicore` will perform core operations by checking your configuration before beginning calculations. 

![](https://docs.google.com/drawings/d/1wGK68NRn5bmhZo_gC2A9sx-AcpIZHVp45ID5_HQKVJ0/pub?w=768&h=192)

<!---
TODO `@jules32`: (keep this?)

    - single goal model with updated data, basically line-by-line to understand the architecture of goal models (access the correct data layers, calc status, calc trend, make sure the final output is standard for what the `scores variables` need. 
    - then calculate all goal models and scores, including pressures, and resilience. 
    - introduce which data layer we modified and which goal model we are using as an example AO
    - a lot of shuffling and bookkeeping. 
    - runs the status, trend in functions.r, but also calculates pressures, resilience, lfs, and overall scores. 
    - score.csv updated, check that in Git tab of RStudio
     book keeping, 
--->

### Prerequisites

Before we begin, make sure you have done the following: 

1. RStudio is configured with Git/GitHub, and you have an up-to-date version of R and RStudio (Chapter \@ref(datascience))
1. Fork the **toolbox-demo** repository into your own GitHub account by going to https://github.com/OHI-Science/toolbox-demo, clicking "Fork" in the upper right corner, and selecting your account
1. Clone the **toolbox-demo** repo from your GitHub account into RStudio
1. Get comfortable: be set up with two screens if possible. You will be following along in RStudio on your own computer while also watching an instructor's screen or following this tutorial.


## Review the Toolbox file ecosystem

<!--- TODO `@ningningj`: toolbox_ecosystem.rmd--->

This was covered in Chapter \@ref(toolbox). In our **toolbox-demo** repo, we have a scenario folder called **region2016**. Remember that the ecosystem structure of any OHI assessment is the same, so as you learn to navigate through and calculate scores in the **toolbox-demo** repository you are also learning how to navigate through and calculate scores in any other OHI assessment repository — yours or anyone else's.

### Run `install_ohicore.r`

If you don't already hav `ohicore` installed, let's do that now. `ohicore` is an R package developed by the OHI team that has all the essential core functions and supporting packages you will use to develop your assessment and calculate scores. You will install `ohicore` one time and then load its library from the `toolbox-training` repository whenever you work on your assessment to gain access to all those functions and packages. 

Let's open and source `install_ohicore.r`. Learn more about `ohicore` in Chapter X. <!---TODO:: where would a section on ohicore go? Maybe need to make a vingette for it and link to it but not have a section here.---> 


## Run `calculate_scores.r`

`calculate_scores.r` is a script that you'll run a lot — both as a whole and piece-by-piece. It will load the libraries you need and `ohicore` will check your book-keeping and configuration, calculate OHI scores, and ultimately save the scores for each goal and dimension in `scores.csv`. The 'dimensions' of OHI goal scores are Status, Trend, Pressures, Resilience, Likely Future State, and overall goal Score. Dimensions are calculated for each goal in a specific order, as we will see below. `calculate_scores.r` will combine information from your tailored repository (your data layers, Status and Trend models, pressures and resilience matrices), and calculate scores with OHI core functions from `ohicore`. 

Open `calculate_scores.r` after navigating into the `region2016` folder. 

![](https://docs.google.com/drawings/d/1uMcbzmBRgjxKVgRqLYnxpbOGIJrm1AbMw7D3E-dUFzk/pub?w=960&h=720)


### Source `configure_toolbox.R`

We will start by **sourcing `configure_toolbox.R`**.

There is output printed to the console that lists all of the layers registered, and ends with any warning messages about the layers themselves. We will explore what is happening in `configure_toolbox.r` and how to interpret these warning messages further on; for now, let's move on since we have not encountered an error. 

```{r configure_toolbox, eval=FALSE}
## run the configure_toolbox.r script to check configuration
source('~/github/toolbox-demo/region2016/configure_toolbox.r')

#   cc_acid
#   cc_slr
# ...
#   tr_travelwarnings
# Warning messages:
# 1: In ohicore::CheckLayers("layers.csv", "layers", flds_id = conf$config$layers_id_fields) :
#   Unused fields...
#     ico_spp_iucn_status: iucn_sid
# 2: In ohicore::CheckLayers("layers.csv", "layers", flds_id = conf$config$layers_id_fields) :
#   Rows duplicated...
#     ico_spp_iucn_status: 816

```

### Run `CalculateAll()`

Now let's **run `CalculateAll()`** and discuss the output. Notice too that we are saving the output to a variable called `scores`. 

> Note: the prefix `ohicore::` is a way to be explicit that the `CalculateAll()` is part of the `ohicore` package.

```{r CalculateAll, eval=FALSE}
## calculate scenario scores
scores = ohicore::CalculateAll(conf, layers)
```

`CalculateAll()` first calculates the Status and Trend for every goal and subgoal. These models are in your tailored repository's `functions.r` (we will explore `functions.r` below). You can choose to add messages to print during calculation like is shown below for Mariculture (MAR).

```{r CalculateAll_output_status, eval=FALSE}
# Running Setup()...
# Calculating Status and Trend for each region for FIS...
# Calculating Status and Trend for each region for MAR...
# 95th percentile for MAR ref pt is: 0.0758396517531756
# ... 
```

Next, we see output as `CalculateAll()` calculates Pressures and Resilience based on the pressures and resilience matrix tables in your tailored repository. For each, `ohicore` lists the subcategories that will be calculated, and identifies any mis-matches between data layers identified but not used or missing. We will learn more about the pressures and resilience matrices later on. <!---TODO: need to develop the pressures/resilience section---> 

```{r CalculateAll_output_pressures, eval=FALSE}
# Calculating Pressures for each region...

# There are 6 pressures subcategories: pollution, alien_species, habitat_destruction, fishing_pressure, climate_change, social
# These goal-elements are in the weighting data layers, but not included in the pressure_matrix.csv:
# LIV-aqf
# These goal-elements are in the pressure_matrix.csv, but not included in the weighting data layers:
# CP-coral, CP-mangrove, CP-saltmarsh, CS-mangrove, CS-saltmarsh, HAB-coral, HAB-mangrove, HAB-saltmarsh, HAB-seagrass, LIV-ph, LIV-tran, CP-seaice_shoreline, HAB-seaice_edge, ECO-wte, LIV-wte, LIV-sb


# Calculating Resilience for each region...

# There are 7 Resilience subcategories: ecological, alien_species, goal, fishing_pressure, habitat_destruction, pollution, social
# These goal-elements are in the resilience_matrix.csv, but not included in the weighting data layers:
# CP-coral, CP-saltmarsh, CS-saltmarsh, HAB-coral, HAB-saltmarsh, HAB-seagrass, CP-mangrove, CS-mangrove, HAB-mangrove, HAB-seaice_edge, CP-seaice_shoreline
```

Finally, we see output as `CalculateAll()` combines the dimensions above in several ways. It calculates the Goal Scores and Likely Future State for each goal and subgoal. Then, it calculates 'supragoals', which are goals that have subgoals, for example Food Provision (FP), which has the subgoals FIS (Wild-caught Fisheries) and Mariculture (MAR). Finally, it calculates the overall Index score for the entire Assessment Area using an area-weighted average. 

```{r CalculateAll_output_etc, eval=FALSE}
# ...
# Calculating Goal Score and Likely Future for each region for FIS...
# Calculating Goal Score and Likely Future for each region for MAR...
# ...
# Calculating post-Index function for each region for FP...
# Calculating post-Index function for each region for LE...
# Calculating Index score for each region for supragoals using goal weights...
# Calculating Likely Future State for each region for supragoals using goal weights...
# Calculating scores for ASSESSMENT AREA (region_id=0) by area weighting...
# Calculating FinalizeScores function...
```

Following all the calculations are the warning messages, which are due to operations within `functions.r`, which you will be able to fix as you tailor your goal models. These warning messages are due to using goal models from the global assessment with just a subset of data from the global assessment we have extracted here for the **toolbox-demo** repository.

```{r CalculateAll_output_warnings, eval=FALSE}
# Warning messages:
# 1: In left_join_impl(x, y, by$x, by$y, suffix$x, suffix$y) :
#   joining factors with different levels, coercing to character vector
# ...
# 8: In max(d$x, na.rm = T) :
#   no non-missing arguments to max; returning -Inf
```

### Save scores variable as `scores.csv`

Finally, we will save the output from `CalculateAll()`, a variable called `scores`, as a comma-separated-value file called `scores.csv`. We can inspect it and see that it is a long-formatted file with four columns for the goal, dimension, numeric region identifier, and score. 

```{r write_scores, eval=FALSE}
## save scores as scores.csv
write.csv(scores, 'scores.csv', na='', row.names=F)
```

|goal |dimension | region_id| score|
|:----|:---------|---------:|-----:|
|AO   |future    |         0| 92.85|
|AO   |future    |         1| 92.85|
|AO   |future    |         2| 92.85|
|...  |...       |       ...|  ... |
|AO   |future    |        17| 92.85|
|AO   |pressures |         1| 37.75|
|AO   |pressures |         2| 37.75|
|...  |...       |       ...|  ... |

We have 17 regions in the **toolbox-demo** repo. An additional region 0 is the area-weighted combination of all regions.

> Note: each region in your assessment will have a numeric region identifer, called a `region_id` or `rgn_id` for short. You can see a list of all regions and corresponding identifiers in [toolbox-demo/region2016/spatial/regions_list.csv](https://github.com/OHI-Science/toolbox-demo/blob/master/region2016/spatial/regions_list.csv)


### Recap of what just happened

We have just successfully run through the basic workflow to calculate OHI scores. We will build on this basic workflow, by exploring the operations above in more detail, and by updating the data, models, and configurations within the **toolbox-demo** repository. 

### A note about error messages

Hopefully this first time through `calculate_scores.r` you did not encounter error messages, but you definitely will as you move ahead. Error messages are often due to typos or miscommunications between what you tell `R` versus what it expects. You will encounter error messages due to `R` itself, and due to `ohicore`. Error messages often have human-friendly messages to alert you to what went wrong, and we are continually improving error messages you'll encounter when you use `ohicore` so you can try to solve them more easily. Some commonly occurring errors and how to fix them can be found in the Troubleshooting section of the manual. Copy-pasting error messages into Google is also one of the best places to start. 


## Tailor a data layer and rerun `calculate_scores.r`

In this example, we will substitute a single global data layer with the same layername (although different data file) with local data and recalculate scores without modifying the goal model itself. The \@ref(calcs_advanced) chapter will show an example for updating goal models. 

It's always a good idea to Restart `R` before you begin something like this to make sure you don't have any variables loaded that will cause problems later on.

### Save and register prepared data layer

<!-- TODO `@ningningj`: -->

<!-- - make a simple, fake toolbox-demo/prep/AO/prep_AO.R. with last step: save in layers folder. (probably keep it simple, not as a full .Rmd. and [here](https://github.com/OHI-Science/toolbox-demo/blob/master/region2016/spatial/regions_list.csv) are the regions for the toolbox-demo repo.  -->
<!-- - and register it too, briefly.   -->

@jules32: I modified an exisiting global data layer from layers folder, instead of simplifying bhi's ao_prep because in bhi example, new layers would require us to modify the goal models as well, which we are not ready to do in this tutorial yet. -->

#### Save data layer
As the last step of [data prep](link to data_prep), we save the newly modified or created data layer in layers folder and register it so that the toolbox knows where to find it. Let's use AO as an example and practice saving and registering your new data. 

Open `toolbox-demo/prep/AO/ao_prep.Rmd` and follow instructions there to save a data layer. Come back to this tutorial after that's done, and we'll continue on to registering the layer. 

#### Register a data layer 

Now you have prepared the data layer(s), let's register it in `layers.csv`. 

`layers.csv`is where the toolbox keeps a record of all data layers - which goal they are used for, file name, column names, etc. It directs the toolbox to access data layers from appropriate places. 

Usually, when you create a new data layer, you'll add a new row in the spreadsheet and fill in the first eight columns (columns A-H), as explained [here](http://ohi-science.org/manual/#register-data-layers-in-layers.csv). But in this excercise, for simiplicity, we modified an existing data layer and renamed it, and you only need to change the "filename". 

Open `region2016/layers.csv` in a spreadsheet software (i.e. Microsoft Excel), and we will replace the "filename" for "ao_access" layer to the new data layer you just saved - "ao_access_demo2017.csv".

### Rerun `calculate_scores.r` 

- see that now `scores.csv` shows up in the git window. Great way to check your work. Which goal do you expect to change?
- and layers.csv, and your layers file

**Checking your work:** Whenever there are changes made (addition, deletion, changes in .csv or r script), you will be notified in the Git window, since Git is tracking changes to your work. So here, since you added a new data layer, and also expect changes to AO scores in `score.csv`. This is a good place to double check whether you have made the right changes.


### Explore `configure_toolbox.r`

So now let's take a closer look, let's check out `configure_toolbox.r`, the first thing that runs. 

`configure_toolbox.r` combines everything required to calculate OHI scores and checks that they are properly formatted, and will minimize potential errors later on. It makes sure that your data and goal models are ready to be used to calculate scores. 

![](https://docs.google.com/drawings/d/1WvHfWe06D2x9cKB7vhWrmvmxuRpmGvzsMs9AjS23g3E/pub?h=450)

> Any time you make a change to a data layer or a goal model and want to recalculate scores, you will need to re-run `configure_toolbox.r` to have `ohicore` operate on the most up-to-date information. You can click "Source" to run all the lines:

> ![](https://docs.google.com/drawings/d/1JvSJKyiwvp92--obTwHT3IYht1XE0823sORJ4FdnX74/pub?h=450)


#### Load libraries and set working directory

<!-- TODO `@ningningj`: check this to see it's complete and a similar to style in the `Run calculate_scores.r section` above -->

<!-- Also, if you are requiring other libraries as you develop your own goal models, this would be the place to load them.  -->

The first two steps set up your working environment: 
- load `ohicore` and R packages (eg. tidyerse, stringr)
- set working directory to your repository

```{r load ohicore and libraries}
## load ohicore and tidyverse (includes dplyr, tidyr, stringr, etc)
if (!"ohicore" %in% (.packages())) {
  suppressWarnings(require(ohicore))
  library(tidyverse)    # install.packages('tidyverse')
  library(stringr)
}

## set working directory to the scenario that contains conf and layers directories
setwd('~/github/toolbox-demo/region2016')
```

#### `ohicore::Conf()`

This function prepares for the next steps of running the toolbox, and calls forth everything you need to calculate scores: 

- all data layers (for goals, pressures, resilience) 
- goal functions, and 
- other OHI parameters that determines how ohi scores are calculated 


```{r Conf(), eval=FALSE}
## load scenario configuration
conf = ohicore::Conf('conf')
```


#### `ohicore::CheckLayers()`

This function checks that data layers are properly formatted and registered (e.g., that each datalayer in layers.csv is present in the layers folder, etc.), and returns a list of all of the layers that are registered. Check to make sure ours is there. This is a gate-keeping step by to make sure the data layers you've entered are in the right format and can be read by `ohicore` properly. 

```{r CheckLayers(), eval=FALSE}
## check that scenario layers files in the \layers folder match layers.csv registration. Layers files are not modified.
ohicore::CheckLayers('layers.csv', 'layers', flds_id=conf$config$layers_id_fields)
```

Warning messages alert you to problems with specific layers: this is showing that there are duplicates in a status layer. These warning messages are not  a problem now (they are a byproduct of extracting this repo based on Global OHI assessments; you'll be changing this layer anyways). 

```{r ohicore_warnings, eval=FALSE}
Warning messages:
1: In ohicore::CheckLayers("layers.csv", "layers", flds_id = conf$config$layers_id_fields) :
  Unused fields...
    ico_spp_iucn_status: iucn_sid
2: In ohicore::CheckLayers("layers.csv", "layers", flds_id = conf$config$layers_id_fields) :
  Rows duplicated...
    ico_spp_iucn_status: 816
```

You'll also encounter error messages as you develop your own assessment. These messages intend to alert you that there are errors in data entry. Some common errors are: 

- improper formatting or missing columns in your data layer
- typos or misnamed columns


#### `ohicore::Layers()`

TODO: explain

This function creates an R object that combines into a single object all the information 
from the layers files and the layers.csv metadata. Individual layers can be accessed as: layer_object_name$data$layer_name???

```{r Layers(), eval=FALSE}
## load scenario layers for ohicore to access. Layers files are not modified.
layers = ohicore::Layers('layers.csv', 'layers')

# (no output)

```

## Explore a goal model in `functions.r`

Remember from `calculate_scores.r` that after configure_toolbox, the next thing that happens is that CalculateScores() runs through the goal models and calcuates status and trend. Status and Trend calculations are contained in `functions.r` in the `conf` folder.

![](https://docs.google.com/drawings/d/1CKNjIORLJOEaV2XW4Z9QuFLN7q1lJ1PaEGg2dSG1-_o/pub?h=450)

`functions.r` is a big list of all goal models in the assessment, each as its own `R` function. You can run all of them at the once or each individually. **Each goal model is an individual R function that calculates status and trend, and you will modify the goal model within the confines of each function**. Let's look at the goal models for Artisanal Fishing Opportunity (AO) as an example. It has models developed from the most recent global assessment as a place for you to start.

> **Tip**: Clicking the bottom left corner of Console will show you a drop-down menu of all functions. It's a shortcut to jump to the appropriate section or goal model

 > ![](https://docs.google.com/drawings/d/1Z2AVtVfIZEd_5GDcmaLb8mRpErKTDzmcbg0SBMxKsxs/pub?h=450)

The following things happen in each goal model:
  
  - load specific data layers (using `ohicore::SelectLayersData()`) 
  - calculate status scores 
  - calculate trend scores 
  - combine status and trend scores 
  - format and return the `scores`


### Load specific data layers with `SelectLayersData()`

`SelectLayersData()` is an `ohicore` function to call the appropriate data layers by its layer name registered in `layers.csv` (eg. "ao_access")
Run this chunk of code and the data layers will be loaded, joined, and ready to be manipulated further: 

```{r load_data, eval=FALSE}

## "select"" is a function from the dplyr package to let you select only the columns you would need

r <- SelectLayersData(layers, layers = 'ao_access', narrow=TRUE) %>%
    select(region_id=id_num, access=val_num)
r <- na.omit(r)

ry <- SelectLayersData(layers, layers = 'ao_need', narrow=TRUE) %>%
    select(region_id = id_num, year, need=val_num) %>%
    left_join(r, by="region_id")

```


> Tip: it's always a good idea to check what your data looks like and make sure there are no glaring errors. A couple of commonly used functions are: head() and str()

### Calculate status 

Once you make sure your data layer has been loaded and joined in the right format, you can start calculate status scores!

<!-- **TODO `@ningningj`: this syntax uses the `tidyverse` and chaining...look xxx to learn more**  -->

This syntax uses the `tidyverse` package that you loaded in `configure_toolbox.r`. It contains the commonly- used, data-wrangling functions you'll need in almost every analysis, and enables chaining (ie. %>%). We'll briefly explain some of the functions below as we encounter them. 

To learn more, take a look at [tidyverse.org](http://tidyverse.org/). This [cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) is also a helpful guide with quick references to each function. 

```{r, eval=FALSE}
# model: this step calculates status scores of all years, using the goal model. 

## "mutate" is another commonly used function from dplyr that allows you to add a new column to the data frame
## Note that "Sustainability" and "status_year" have been defined at the start of the AO function 
  Sustainability=1.0
  status_year = 2015

  ry <- ry %>%
    mutate(Du = (1 - need) * (1 - access)) %>%
    mutate(status = (1 - Du) * Sustainability)

# status: status scores are typically the most recent year of all the years you have calculated. 

  r.status <- ry %>%
    filter(year==status_year) %>%
    select(region_id, status) %>%
    mutate(status=status*100)
```

### Calculate trend 

Trend scores are typically based on linear regression of status scores from the most recent five years. 

```{r, eval=FALSE}
 # choose trend years (eg. most recent five years)

  trend_years <- (status_year-4):(status_year)
  adj_trend_year <- min(trend_years)

  r.trend = ry %>%
    group_by(region_id) %>% 
    # linear model: 
    do(mdl = lm(status ~ year, data=., subset=year %in% trend_years),
       adjust_trend = .$status[.$year == adj_trend_year]) %>%
    # extract the coefficient of year and produce a trend score
    summarize(region_id, trend = ifelse(coef(mdl)['year']==0, 0, coef(mdl)['year']/adjust_trend * 5)) %>%
    # make sure that the scores are between -1 and 1
    mutate(trend = ifelse(trend>1, 1, trend)) %>%
    mutate(trend = ifelse(trend<(-1), (-1), trend)) %>%
    mutate(trend = round(trend, 4))

```

### Scores variable: combining status and trend

Choose only region_id and score, and add two more columns identifying score dimension (status or trend) and goal name. 
```{r, eval=FALSE}
 scores = r.status %>%
    select(region_id, score=status) %>%
    mutate(dimension='status') %>%
    rbind(
      r.trend %>%
        select(region_id, score=trend) %>%
        mutate(dimension='trend')) %>%
    mutate(goal='AO')
```

The scores variable is something that you'll see at the end of every goal model; `ohicore` will combine these all together when `CalculateAll()` runs.

## Tailor goal model using original data layers

Modifying a goal model involves editing the operations within that goal's model in `functions.r`. 

First let's restart R and source `configure_toolbox.r`. We can do this from either `calculate_scores.r` or from `configure_toolbox.r` itself.

Now, let's go to `functions.r` and go back to the AO model. Let's do something pretty simple to tailor the goal model. Let's say we just wanted to divide the variable `Du` by 2 in the equation. 

```{r tailor AO goal model, eval=FALSE}
 ry <- ry %>%
    mutate(Du = (1 - need) * (1 - access)) %>%
    mutate(status = (1 - Du/2) * sustainability)
```

We can run the rest of the AO function line-by-line and inspect the scores variable at the end to see if everything looks OK. 

It looks OK to me, so let's run the rest of `calculate_scores.r`, and use Git's differencing feature to see how our scores have changed. This is a great way to double-check and error-check that things are working the way you expected. 

## Tailor goal model using new data layers
 
Now, we are going to tailor a goal model by adding a new data layer, so it's the combination of what we've gone through above. 

### Save and register a new prepared data layer.

TODO: create another AO prep.r

Now, to register this layer, we'll need to add a new row to `layers.csv`

Now, in `functions.r`, we'll need to use SelectLayersData() to access your new layer, and then use it in a calculation, using the same workflow from above.
 
 
 
end 2-hour tutorial.

<!---next steps after Eva training: 

## Update pressures and resilience matrices

- PlotFlower, PlotMap
- updating pressures/resilience matrices


--->
